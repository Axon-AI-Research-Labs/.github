ğŸŒŒ Welcome to Axon: AI Research Lab ğŸš€ğŸ¤–

This organization is a collaborative platform dedicated to:
- âœ¨ Implementing research papers in artificial intelligence.
- ğŸ§  Conducting our own original research projects.
- ğŸ“‘ Publishing research papers to contribute to the global AI community.

Our mission is to bridge the gap between theory and practice, by providing:

ğŸ”¬ High-quality, reproducible implementations of seminal and contemporary AI works (e.g., InstructGPT, LLaMA, Transformers, Diffusion Models, RLHF, etc.)

ğŸ“ Novel contributions through our own research and publications.

Together, we aim to push forward the boundaries of artificial intelligence while keeping our work open, collaborative, and impactful. ğŸŒğŸ’¡


## ğŸ“š Featured Publications  

<table>
<tr>
  <td width="33%">
    <a href="https://arxiv.org/abs/2504.08744">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/ExpertRAG.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>ExpertRAG: Efficient RAG with Mixture of Experts -- Optimizing Context Retrieval for Adaptive LLM Responses</b></p>
  </td>
  <td width="33%">
    <a href="https://arxiv.org/abs/2507.22915">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/Math.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>Mitigation of Hallucination in LLM</b></p>
  </td>
  <td width="33%">
    <a href="https://arxiv.org/abs/2507.10581">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/theory.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>Universal Approximation in Transformers</b></p>
  </td>
</tr>
<tr>
  <td width="33%">
    <a href="https://arxiv.org/abs/2504.03662">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/Galvatron.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>Galvatron: Large Transformer Training</b></p>
  </td>
  <td width="33%">
    <a href="http://dx.doi.org/10.13140/RG.2.2.25049.02400">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/Mixture.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>Mixture of Transformers: Macro-Level Gating for Sparse Activation in LLM Ensembles</b></p>
  </td>
  <td width="33%">
    <a href="http://dx.doi.org/10.13140/RG.2.2.22814.24643">
      <img src="https://github.com/Axon-AI-Research-Labs/assists-/blob/main/Thesis.jpg" width="100%" height="400">
    </a>
    <p align="center"><b>Bachelor Thesis: AI Engine â€“ Deep Learning and Neural Network Engine</b></p>
  </td>
</tr>
</table>
